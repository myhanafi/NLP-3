{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAaQKrnYDe85D7Li/q6na8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myhanafi/NLP-3/blob/main/NLP_PERTEMUAN_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dasar Text-Preprocessing dengan Python**"
      ],
      "metadata": {
        "id": "uwX8DT-WckG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xkYa5aPRcryI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs3rPrZrYkbV",
        "outputId": "86cb6612-637f-416c-9d5a-83caed6aead7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "Hit Enter to continue:  l\n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "Hit Enter to continue: 1\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "Hit Enter to continue: lin_thesaurus\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] punkt............... Punkt Tokenizer Models\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "Hit Enter to continue: reuters\n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] stopwords........... Stopwords Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "Hit Enter to continue: toolbox\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet2021......... Open English Wordnet 2021\n",
            "  [ ] wordnet31........... Wordnet 3.1\n",
            "  [ ] wordnet............. WordNet\n",
            "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
            "  [ ] words............... Word Lists\n",
            "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
            "                           English Prose\n",
            "\n",
            "Collections:\n",
            "  [ ] all-corpora......... All the corpora\n",
            "Hit Enter to continue: all-corpora\n",
            "  [ ] all-nltk............ All packages available on nltk_data gh-pages\n",
            "                           branch\n",
            "  [ ] all................. All packages\n",
            "  [ ] book................ Everything used in the NLTK Book\n",
            "  [ ] popular............. Popular packages\n",
            "  [ ] tests............... Packages for running tests\n",
            "  [ ] third-party......... Third-party data packages\n",
            "\n",
            "([*] marks installed packages)\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all-nltk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading collection 'all-nltk'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Unzipping corpora/alpino.zip.\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/basque_grammars.zip.\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Unzipping corpora/biocreative_ppi.zip.\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown.zip.\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown_tei.zip.\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_cat.zip.\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_esp.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/comparative_sentences.zip.\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Unzipping corpora/crubadan.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Unzipping corpora/dolch.zip.\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Unzipping corpora/europarl_raw.zip.\n",
            "       | Downloading package extended_omw to /root/nltk_data...\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Unzipping corpora/floresta.zip.\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v15.zip.\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v17.zip.\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Unzipping corpora/indian.zip.\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Unzipping corpora/kimmo.zip.\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/large_grammars.zip.\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Unzipping corpora/lin_thesaurus.zip.\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Unzipping corpora/mac_morpho.zip.\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Unzipping models/moses_sample.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Unzipping corpora/mte_teip5.zip.\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Unzipping misc/mwa_ppdb.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       | Downloading package omw-1.4 to /root/nltk_data...\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Unzipping corpora/opinion_lexicon.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Unzipping corpora/paradigms.zip.\n",
            "       | Downloading package pe08 to /root/nltk_data...\n",
            "       |   Unzipping corpora/pe08.zip.\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Unzipping misc/perluniprops.zip.\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Unzipping corpora/pil.zip.\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Unzipping corpora/pl196x.zip.\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Unzipping stemmers/porter_test.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Unzipping corpora/problem_reports.zip.\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_1.zip.\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_2.zip.\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Unzipping corpora/pros_cons.zip.\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Unzipping corpora/ptb.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Unzipping corpora/qc.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Unzipping stemmers/rslp.zip.\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Unzipping corpora/rte.zip.\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/sample_grammars.zip.\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentence_polarity.zip.\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentiwordnet.zip.\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/sinica_treebank.zip.\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Unzipping corpora/smultron.zip.\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/spanish_grammars.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Unzipping corpora/subjectivity.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Unzipping corpora/switchboard.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Unzipping taggers/universal_tagset.zip.\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet.zip.\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet3.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Unzipping models/wmt15_eval.zip.\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Unzipping models/word2vec_sample.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       | Downloading package wordnet2021 to /root/nltk_data...\n",
            "       | Downloading package wordnet31 to /root/nltk_data...\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Unzipping corpora/ycoe.zip.\n",
            "       | \n",
            "     Done downloading collection all-nltk\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7AsC0PPeGT0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instal modul sastrawi untuk teks bahasa Indonesia**"
      ],
      "metadata": {
        "id": "AV5cFSbgeM8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sastrawi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqEG-vrPZwu8",
        "outputId": "5a1f2fa2-c6fa-41d2-83bb-1d6660888f3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 209 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ],
      "metadata": {
        "id": "_lFmoqO6Z-Ov"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ],
      "metadata": {
        "id": "6O6B2abiaK6g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Pelajaran NLP dapat digunakan untuk Penelitian atau pengembangan menjadi Thesis atau paper penelitian'"
      ],
      "metadata": {
        "id": "4ib5G-i1aL2c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output   = stemmer.stem(sentence)"
      ],
      "metadata": {
        "id": "swBsP8OgaMqW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtTuL__XabeL",
        "outputId": "d1c3b363-0e8f-4fd7-d322-e9da1f7ac4e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ajar nlp dapat guna untuk teliti atau kembang jadi thesis atau paper teliti\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Menghapus karakter angka.**"
      ],
      "metadata": {
        "id": "npUxzonIef-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kalimat = \" Indonesia menempati ranking viva pada urutan 143 dunia, Sedangkan Brasil menempati ranking 1 Dunia\""
      ],
      "metadata": {
        "id": "QDDEXGWQaj-o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower_case = kalimat.lower()"
      ],
      "metadata": {
        "id": "JI5Z-gDvaofd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lower_case)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrIDxt3FavSZ",
        "outputId": "f8ea46f2-3622-4d1d-acbf-02d3ecea24f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " indonesia menempati ranking viva pada urutan 143 dunia, sedangkan brasil menempati ranking 1 dunia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re # impor modul regular expression"
      ],
      "metadata": {
        "id": "uMZKb43gaysz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kalimat = \"Indonesia menempati ranking viva pada urutan 143 dunia, Sedangkan Brasil menempati ranking 1 Dunia\""
      ],
      "metadata": {
        "id": "1xeL2VNya3T7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hasil = re.sub(r\"\\d+\", \"\", kalimat)\n",
        "print(hasil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f-ns4RVbAwJ",
        "outputId": "c42803cf-2d03-4a76-9c24-0dd1ee35fa5a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indonesia menempati ranking viva pada urutan  dunia, Sedangkan Brasil menempati ranking  Dunia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer    \n",
        "ps = PorterStemmer() \n",
        "\n",
        "kata = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\"] \n",
        "kata = [\"working\",\"forgotten\",\"worries\",\"horrible\",\"trusted\",\"worry\",\"needs\",\"effortless\"]\n",
        "  \n",
        "for k in kata: \n",
        "    print(k, \" : \", ps.stem(k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIY5YX1zbYUM",
        "outputId": "357ff5e9-94a0-4521-e2a5-3a37545faa48"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working  :  work\n",
            "forgotten  :  forgotten\n",
            "worries  :  worri\n",
            "horrible  :  horribl\n",
            "trusted  :  trust\n",
            "worry  :  worri\n",
            "needs  :  need\n",
            "effortless  :  effortless\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bahasa Indonesia using Sastrawi**"
      ],
      "metadata": {
        "id": "T6gD2ucGcHhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ],
      "metadata": {
        "id": "Mk960x0ibkZU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kalimat = \"mengerjakan Kuliah master itu kadang capek, banyak tugas, harus banyak baca paper, Banyak nulis.\""
      ],
      "metadata": {
        "id": "yK0Slft5bq6L"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hasil = stemmer.stem(kalimat)"
      ],
      "metadata": {
        "id": "5qGwISFXbu0Y"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hasil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbJtUD8Qb0EZ",
        "outputId": "cc99b9fd-1157-44fe-e044-d34f2f7cdad8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kerja kuliah master itu kadang capek banyak tugas harus banyak baca paper banyak nulis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "print(stopwords.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZCS6FXb_PXLJ",
        "outputId": "ebb5172c-bd67-4b95-e8ec-98ebe47ae78d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-41b67889ccf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As7H51ZePr9Z",
        "outputId": "d0c3bd89-ac73-4812-f5b0-1763a4bdc6ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "print(stopwords.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddF-c630P0Jf",
        "outputId": "06347559-6716-409c-a320-aaddb8502f43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DOivcXpQFz_",
        "outputId": "5f6c95c7-c18b-4274-fb5f-ccd26e939f92"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "paragraf = \"\"\"Siapa yang menanam akan menuai. Siapa yang berbuat baik akan dibalas \n",
        "dengan perbuatan baik. Begitu juga sebaliknya. Orang yang menanam \n",
        "keburukan akan menuai hasil keburukannya sendiri.\"\"\"\n",
        "kata = word_tokenize(paragraf)\n",
        "print(kata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wjAPKiPQNdR",
        "outputId": "c683e070-321c-4c52-91e4-09baef3db825"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Siapa', 'yang', 'menanam', 'akan', 'menuai', '.', 'Siapa', 'yang', 'berbuat', 'baik', 'akan', 'dibalas', 'dengan', 'perbuatan', 'baik', '.', 'Begitu', 'juga', 'sebaliknya', '.', 'Orang', 'yang', 'menanam', 'keburukan', 'akan', 'menuai', 'hasil', 'keburukannya', 'sendiri', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopwords.words('indonesian')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLda9-hJQQ0C",
        "outputId": "4603e4b7-2c31-465a-c4e5-f898f8e5d909"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ada',\n",
              " 'adalah',\n",
              " 'adanya',\n",
              " 'adapun',\n",
              " 'agak',\n",
              " 'agaknya',\n",
              " 'agar',\n",
              " 'akan',\n",
              " 'akankah',\n",
              " 'akhir',\n",
              " 'akhiri',\n",
              " 'akhirnya',\n",
              " 'aku',\n",
              " 'akulah',\n",
              " 'amat',\n",
              " 'amatlah',\n",
              " 'anda',\n",
              " 'andalah',\n",
              " 'antar',\n",
              " 'antara',\n",
              " 'antaranya',\n",
              " 'apa',\n",
              " 'apaan',\n",
              " 'apabila',\n",
              " 'apakah',\n",
              " 'apalagi',\n",
              " 'apatah',\n",
              " 'artinya',\n",
              " 'asal',\n",
              " 'asalkan',\n",
              " 'atas',\n",
              " 'atau',\n",
              " 'ataukah',\n",
              " 'ataupun',\n",
              " 'awal',\n",
              " 'awalnya',\n",
              " 'bagai',\n",
              " 'bagaikan',\n",
              " 'bagaimana',\n",
              " 'bagaimanakah',\n",
              " 'bagaimanapun',\n",
              " 'bagi',\n",
              " 'bagian',\n",
              " 'bahkan',\n",
              " 'bahwa',\n",
              " 'bahwasanya',\n",
              " 'baik',\n",
              " 'bakal',\n",
              " 'bakalan',\n",
              " 'balik',\n",
              " 'banyak',\n",
              " 'bapak',\n",
              " 'baru',\n",
              " 'bawah',\n",
              " 'beberapa',\n",
              " 'begini',\n",
              " 'beginian',\n",
              " 'beginikah',\n",
              " 'beginilah',\n",
              " 'begitu',\n",
              " 'begitukah',\n",
              " 'begitulah',\n",
              " 'begitupun',\n",
              " 'bekerja',\n",
              " 'belakang',\n",
              " 'belakangan',\n",
              " 'belum',\n",
              " 'belumlah',\n",
              " 'benar',\n",
              " 'benarkah',\n",
              " 'benarlah',\n",
              " 'berada',\n",
              " 'berakhir',\n",
              " 'berakhirlah',\n",
              " 'berakhirnya',\n",
              " 'berapa',\n",
              " 'berapakah',\n",
              " 'berapalah',\n",
              " 'berapapun',\n",
              " 'berarti',\n",
              " 'berawal',\n",
              " 'berbagai',\n",
              " 'berdatangan',\n",
              " 'beri',\n",
              " 'berikan',\n",
              " 'berikut',\n",
              " 'berikutnya',\n",
              " 'berjumlah',\n",
              " 'berkali-kali',\n",
              " 'berkata',\n",
              " 'berkehendak',\n",
              " 'berkeinginan',\n",
              " 'berkenaan',\n",
              " 'berlainan',\n",
              " 'berlalu',\n",
              " 'berlangsung',\n",
              " 'berlebihan',\n",
              " 'bermacam',\n",
              " 'bermacam-macam',\n",
              " 'bermaksud',\n",
              " 'bermula',\n",
              " 'bersama',\n",
              " 'bersama-sama',\n",
              " 'bersiap',\n",
              " 'bersiap-siap',\n",
              " 'bertanya',\n",
              " 'bertanya-tanya',\n",
              " 'berturut',\n",
              " 'berturut-turut',\n",
              " 'bertutur',\n",
              " 'berujar',\n",
              " 'berupa',\n",
              " 'besar',\n",
              " 'betul',\n",
              " 'betulkah',\n",
              " 'biasa',\n",
              " 'biasanya',\n",
              " 'bila',\n",
              " 'bilakah',\n",
              " 'bisa',\n",
              " 'bisakah',\n",
              " 'boleh',\n",
              " 'bolehkah',\n",
              " 'bolehlah',\n",
              " 'buat',\n",
              " 'bukan',\n",
              " 'bukankah',\n",
              " 'bukanlah',\n",
              " 'bukannya',\n",
              " 'bulan',\n",
              " 'bung',\n",
              " 'cara',\n",
              " 'caranya',\n",
              " 'cukup',\n",
              " 'cukupkah',\n",
              " 'cukuplah',\n",
              " 'cuma',\n",
              " 'dahulu',\n",
              " 'dalam',\n",
              " 'dan',\n",
              " 'dapat',\n",
              " 'dari',\n",
              " 'daripada',\n",
              " 'datang',\n",
              " 'dekat',\n",
              " 'demi',\n",
              " 'demikian',\n",
              " 'demikianlah',\n",
              " 'dengan',\n",
              " 'depan',\n",
              " 'di',\n",
              " 'dia',\n",
              " 'diakhiri',\n",
              " 'diakhirinya',\n",
              " 'dialah',\n",
              " 'diantara',\n",
              " 'diantaranya',\n",
              " 'diberi',\n",
              " 'diberikan',\n",
              " 'diberikannya',\n",
              " 'dibuat',\n",
              " 'dibuatnya',\n",
              " 'didapat',\n",
              " 'didatangkan',\n",
              " 'digunakan',\n",
              " 'diibaratkan',\n",
              " 'diibaratkannya',\n",
              " 'diingat',\n",
              " 'diingatkan',\n",
              " 'diinginkan',\n",
              " 'dijawab',\n",
              " 'dijelaskan',\n",
              " 'dijelaskannya',\n",
              " 'dikarenakan',\n",
              " 'dikatakan',\n",
              " 'dikatakannya',\n",
              " 'dikerjakan',\n",
              " 'diketahui',\n",
              " 'diketahuinya',\n",
              " 'dikira',\n",
              " 'dilakukan',\n",
              " 'dilalui',\n",
              " 'dilihat',\n",
              " 'dimaksud',\n",
              " 'dimaksudkan',\n",
              " 'dimaksudkannya',\n",
              " 'dimaksudnya',\n",
              " 'diminta',\n",
              " 'dimintai',\n",
              " 'dimisalkan',\n",
              " 'dimulai',\n",
              " 'dimulailah',\n",
              " 'dimulainya',\n",
              " 'dimungkinkan',\n",
              " 'dini',\n",
              " 'dipastikan',\n",
              " 'diperbuat',\n",
              " 'diperbuatnya',\n",
              " 'dipergunakan',\n",
              " 'diperkirakan',\n",
              " 'diperlihatkan',\n",
              " 'diperlukan',\n",
              " 'diperlukannya',\n",
              " 'dipersoalkan',\n",
              " 'dipertanyakan',\n",
              " 'dipunyai',\n",
              " 'diri',\n",
              " 'dirinya',\n",
              " 'disampaikan',\n",
              " 'disebut',\n",
              " 'disebutkan',\n",
              " 'disebutkannya',\n",
              " 'disini',\n",
              " 'disinilah',\n",
              " 'ditambahkan',\n",
              " 'ditandaskan',\n",
              " 'ditanya',\n",
              " 'ditanyai',\n",
              " 'ditanyakan',\n",
              " 'ditegaskan',\n",
              " 'ditujukan',\n",
              " 'ditunjuk',\n",
              " 'ditunjuki',\n",
              " 'ditunjukkan',\n",
              " 'ditunjukkannya',\n",
              " 'ditunjuknya',\n",
              " 'dituturkan',\n",
              " 'dituturkannya',\n",
              " 'diucapkan',\n",
              " 'diucapkannya',\n",
              " 'diungkapkan',\n",
              " 'dong',\n",
              " 'dua',\n",
              " 'dulu',\n",
              " 'empat',\n",
              " 'enggak',\n",
              " 'enggaknya',\n",
              " 'entah',\n",
              " 'entahlah',\n",
              " 'guna',\n",
              " 'gunakan',\n",
              " 'hal',\n",
              " 'hampir',\n",
              " 'hanya',\n",
              " 'hanyalah',\n",
              " 'hari',\n",
              " 'harus',\n",
              " 'haruslah',\n",
              " 'harusnya',\n",
              " 'hendak',\n",
              " 'hendaklah',\n",
              " 'hendaknya',\n",
              " 'hingga',\n",
              " 'ia',\n",
              " 'ialah',\n",
              " 'ibarat',\n",
              " 'ibaratkan',\n",
              " 'ibaratnya',\n",
              " 'ibu',\n",
              " 'ikut',\n",
              " 'ingat',\n",
              " 'ingat-ingat',\n",
              " 'ingin',\n",
              " 'inginkah',\n",
              " 'inginkan',\n",
              " 'ini',\n",
              " 'inikah',\n",
              " 'inilah',\n",
              " 'itu',\n",
              " 'itukah',\n",
              " 'itulah',\n",
              " 'jadi',\n",
              " 'jadilah',\n",
              " 'jadinya',\n",
              " 'jangan',\n",
              " 'jangankan',\n",
              " 'janganlah',\n",
              " 'jauh',\n",
              " 'jawab',\n",
              " 'jawaban',\n",
              " 'jawabnya',\n",
              " 'jelas',\n",
              " 'jelaskan',\n",
              " 'jelaslah',\n",
              " 'jelasnya',\n",
              " 'jika',\n",
              " 'jikalau',\n",
              " 'juga',\n",
              " 'jumlah',\n",
              " 'jumlahnya',\n",
              " 'justru',\n",
              " 'kala',\n",
              " 'kalau',\n",
              " 'kalaulah',\n",
              " 'kalaupun',\n",
              " 'kalian',\n",
              " 'kami',\n",
              " 'kamilah',\n",
              " 'kamu',\n",
              " 'kamulah',\n",
              " 'kan',\n",
              " 'kapan',\n",
              " 'kapankah',\n",
              " 'kapanpun',\n",
              " 'karena',\n",
              " 'karenanya',\n",
              " 'kasus',\n",
              " 'kata',\n",
              " 'katakan',\n",
              " 'katakanlah',\n",
              " 'katanya',\n",
              " 'ke',\n",
              " 'keadaan',\n",
              " 'kebetulan',\n",
              " 'kecil',\n",
              " 'kedua',\n",
              " 'keduanya',\n",
              " 'keinginan',\n",
              " 'kelamaan',\n",
              " 'kelihatan',\n",
              " 'kelihatannya',\n",
              " 'kelima',\n",
              " 'keluar',\n",
              " 'kembali',\n",
              " 'kemudian',\n",
              " 'kemungkinan',\n",
              " 'kemungkinannya',\n",
              " 'kenapa',\n",
              " 'kepada',\n",
              " 'kepadanya',\n",
              " 'kesampaian',\n",
              " 'keseluruhan',\n",
              " 'keseluruhannya',\n",
              " 'keterlaluan',\n",
              " 'ketika',\n",
              " 'khususnya',\n",
              " 'kini',\n",
              " 'kinilah',\n",
              " 'kira',\n",
              " 'kira-kira',\n",
              " 'kiranya',\n",
              " 'kita',\n",
              " 'kitalah',\n",
              " 'kok',\n",
              " 'kurang',\n",
              " 'lagi',\n",
              " 'lagian',\n",
              " 'lah',\n",
              " 'lain',\n",
              " 'lainnya',\n",
              " 'lalu',\n",
              " 'lama',\n",
              " 'lamanya',\n",
              " 'lanjut',\n",
              " 'lanjutnya',\n",
              " 'lebih',\n",
              " 'lewat',\n",
              " 'lima',\n",
              " 'luar',\n",
              " 'macam',\n",
              " 'maka',\n",
              " 'makanya',\n",
              " 'makin',\n",
              " 'malah',\n",
              " 'malahan',\n",
              " 'mampu',\n",
              " 'mampukah',\n",
              " 'mana',\n",
              " 'manakala',\n",
              " 'manalagi',\n",
              " 'masa',\n",
              " 'masalah',\n",
              " 'masalahnya',\n",
              " 'masih',\n",
              " 'masihkah',\n",
              " 'masing',\n",
              " 'masing-masing',\n",
              " 'mau',\n",
              " 'maupun',\n",
              " 'melainkan',\n",
              " 'melakukan',\n",
              " 'melalui',\n",
              " 'melihat',\n",
              " 'melihatnya',\n",
              " 'memang',\n",
              " 'memastikan',\n",
              " 'memberi',\n",
              " 'memberikan',\n",
              " 'membuat',\n",
              " 'memerlukan',\n",
              " 'memihak',\n",
              " 'meminta',\n",
              " 'memintakan',\n",
              " 'memisalkan',\n",
              " 'memperbuat',\n",
              " 'mempergunakan',\n",
              " 'memperkirakan',\n",
              " 'memperlihatkan',\n",
              " 'mempersiapkan',\n",
              " 'mempersoalkan',\n",
              " 'mempertanyakan',\n",
              " 'mempunyai',\n",
              " 'memulai',\n",
              " 'memungkinkan',\n",
              " 'menaiki',\n",
              " 'menambahkan',\n",
              " 'menandaskan',\n",
              " 'menanti',\n",
              " 'menanti-nanti',\n",
              " 'menantikan',\n",
              " 'menanya',\n",
              " 'menanyai',\n",
              " 'menanyakan',\n",
              " 'mendapat',\n",
              " 'mendapatkan',\n",
              " 'mendatang',\n",
              " 'mendatangi',\n",
              " 'mendatangkan',\n",
              " 'menegaskan',\n",
              " 'mengakhiri',\n",
              " 'mengapa',\n",
              " 'mengatakan',\n",
              " 'mengatakannya',\n",
              " 'mengenai',\n",
              " 'mengerjakan',\n",
              " 'mengetahui',\n",
              " 'menggunakan',\n",
              " 'menghendaki',\n",
              " 'mengibaratkan',\n",
              " 'mengibaratkannya',\n",
              " 'mengingat',\n",
              " 'mengingatkan',\n",
              " 'menginginkan',\n",
              " 'mengira',\n",
              " 'mengucapkan',\n",
              " 'mengucapkannya',\n",
              " 'mengungkapkan',\n",
              " 'menjadi',\n",
              " 'menjawab',\n",
              " 'menjelaskan',\n",
              " 'menuju',\n",
              " 'menunjuk',\n",
              " 'menunjuki',\n",
              " 'menunjukkan',\n",
              " 'menunjuknya',\n",
              " 'menurut',\n",
              " 'menuturkan',\n",
              " 'menyampaikan',\n",
              " 'menyangkut',\n",
              " 'menyatakan',\n",
              " 'menyebutkan',\n",
              " 'menyeluruh',\n",
              " 'menyiapkan',\n",
              " 'merasa',\n",
              " 'mereka',\n",
              " 'merekalah',\n",
              " 'merupakan',\n",
              " 'meski',\n",
              " 'meskipun',\n",
              " 'meyakini',\n",
              " 'meyakinkan',\n",
              " 'minta',\n",
              " 'mirip',\n",
              " 'misal',\n",
              " 'misalkan',\n",
              " 'misalnya',\n",
              " 'mula',\n",
              " 'mulai',\n",
              " 'mulailah',\n",
              " 'mulanya',\n",
              " 'mungkin',\n",
              " 'mungkinkah',\n",
              " 'nah',\n",
              " 'naik',\n",
              " 'namun',\n",
              " 'nanti',\n",
              " 'nantinya',\n",
              " 'nyaris',\n",
              " 'nyatanya',\n",
              " 'oleh',\n",
              " 'olehnya',\n",
              " 'pada',\n",
              " 'padahal',\n",
              " 'padanya',\n",
              " 'pak',\n",
              " 'paling',\n",
              " 'panjang',\n",
              " 'pantas',\n",
              " 'para',\n",
              " 'pasti',\n",
              " 'pastilah',\n",
              " 'penting',\n",
              " 'pentingnya',\n",
              " 'per',\n",
              " 'percuma',\n",
              " 'perlu',\n",
              " 'perlukah',\n",
              " 'perlunya',\n",
              " 'pernah',\n",
              " 'persoalan',\n",
              " 'pertama',\n",
              " 'pertama-tama',\n",
              " 'pertanyaan',\n",
              " 'pertanyakan',\n",
              " 'pihak',\n",
              " 'pihaknya',\n",
              " 'pukul',\n",
              " 'pula',\n",
              " 'pun',\n",
              " 'punya',\n",
              " 'rasa',\n",
              " 'rasanya',\n",
              " 'rata',\n",
              " 'rupanya',\n",
              " 'saat',\n",
              " 'saatnya',\n",
              " 'saja',\n",
              " 'sajalah',\n",
              " 'saling',\n",
              " 'sama',\n",
              " 'sama-sama',\n",
              " 'sambil',\n",
              " 'sampai',\n",
              " 'sampai-sampai',\n",
              " 'sampaikan',\n",
              " 'sana',\n",
              " 'sangat',\n",
              " 'sangatlah',\n",
              " 'satu',\n",
              " 'saya',\n",
              " 'sayalah',\n",
              " 'se',\n",
              " 'sebab',\n",
              " 'sebabnya',\n",
              " 'sebagai',\n",
              " 'sebagaimana',\n",
              " 'sebagainya',\n",
              " 'sebagian',\n",
              " 'sebaik',\n",
              " 'sebaik-baiknya',\n",
              " 'sebaiknya',\n",
              " 'sebaliknya',\n",
              " 'sebanyak',\n",
              " 'sebegini',\n",
              " 'sebegitu',\n",
              " 'sebelum',\n",
              " 'sebelumnya',\n",
              " 'sebenarnya',\n",
              " 'seberapa',\n",
              " 'sebesar',\n",
              " 'sebetulnya',\n",
              " 'sebisanya',\n",
              " 'sebuah',\n",
              " 'sebut',\n",
              " 'sebutlah',\n",
              " 'sebutnya',\n",
              " 'secara',\n",
              " 'secukupnya',\n",
              " 'sedang',\n",
              " 'sedangkan',\n",
              " 'sedemikian',\n",
              " 'sedikit',\n",
              " 'sedikitnya',\n",
              " 'seenaknya',\n",
              " 'segala',\n",
              " 'segalanya',\n",
              " 'segera',\n",
              " 'seharusnya',\n",
              " 'sehingga',\n",
              " 'seingat',\n",
              " 'sejak',\n",
              " 'sejauh',\n",
              " 'sejenak',\n",
              " 'sejumlah',\n",
              " 'sekadar',\n",
              " 'sekadarnya',\n",
              " 'sekali',\n",
              " 'sekali-kali',\n",
              " 'sekalian',\n",
              " 'sekaligus',\n",
              " 'sekalipun',\n",
              " 'sekarang',\n",
              " 'sekarang',\n",
              " 'sekecil',\n",
              " 'seketika',\n",
              " 'sekiranya',\n",
              " 'sekitar',\n",
              " 'sekitarnya',\n",
              " 'sekurang-kurangnya',\n",
              " 'sekurangnya',\n",
              " 'sela',\n",
              " 'selain',\n",
              " 'selaku',\n",
              " 'selalu',\n",
              " 'selama',\n",
              " 'selama-lamanya',\n",
              " 'selamanya',\n",
              " 'selanjutnya',\n",
              " 'seluruh',\n",
              " 'seluruhnya',\n",
              " 'semacam',\n",
              " 'semakin',\n",
              " 'semampu',\n",
              " 'semampunya',\n",
              " 'semasa',\n",
              " 'semasih',\n",
              " 'semata',\n",
              " 'semata-mata',\n",
              " 'semaunya',\n",
              " 'sementara',\n",
              " 'semisal',\n",
              " 'semisalnya',\n",
              " 'sempat',\n",
              " 'semua',\n",
              " 'semuanya',\n",
              " 'semula',\n",
              " 'sendiri',\n",
              " 'sendirian',\n",
              " 'sendirinya',\n",
              " 'seolah',\n",
              " 'seolah-olah',\n",
              " 'seorang',\n",
              " 'sepanjang',\n",
              " 'sepantasnya',\n",
              " 'sepantasnyalah',\n",
              " 'seperlunya',\n",
              " 'seperti',\n",
              " 'sepertinya',\n",
              " 'sepihak',\n",
              " 'sering',\n",
              " 'seringnya',\n",
              " 'serta',\n",
              " 'serupa',\n",
              " 'sesaat',\n",
              " 'sesama',\n",
              " 'sesampai',\n",
              " 'sesegera',\n",
              " 'sesekali',\n",
              " 'seseorang',\n",
              " 'sesuatu',\n",
              " 'sesuatunya',\n",
              " 'sesudah',\n",
              " 'sesudahnya',\n",
              " 'setelah',\n",
              " 'setempat',\n",
              " 'setengah',\n",
              " 'seterusnya',\n",
              " 'setiap',\n",
              " 'setiba',\n",
              " 'setibanya',\n",
              " 'setidak-tidaknya',\n",
              " 'setidaknya',\n",
              " 'setinggi',\n",
              " 'seusai',\n",
              " 'sewaktu',\n",
              " 'siap',\n",
              " 'siapa',\n",
              " 'siapakah',\n",
              " 'siapapun',\n",
              " 'sini',\n",
              " 'sinilah',\n",
              " 'soal',\n",
              " 'soalnya',\n",
              " 'suatu',\n",
              " 'sudah',\n",
              " 'sudahkah',\n",
              " 'sudahlah',\n",
              " 'supaya',\n",
              " 'tadi',\n",
              " 'tadinya',\n",
              " 'tahu',\n",
              " 'tahun',\n",
              " 'tak',\n",
              " 'tambah',\n",
              " 'tambahnya',\n",
              " 'tampak',\n",
              " 'tampaknya',\n",
              " 'tandas',\n",
              " 'tandasnya',\n",
              " 'tanpa',\n",
              " 'tanya',\n",
              " 'tanyakan',\n",
              " 'tanyanya',\n",
              " 'tapi',\n",
              " 'tegas',\n",
              " 'tegasnya',\n",
              " 'telah',\n",
              " 'tempat',\n",
              " 'tengah',\n",
              " 'tentang',\n",
              " 'tentu',\n",
              " 'tentulah',\n",
              " 'tentunya',\n",
              " 'tepat',\n",
              " 'terakhir',\n",
              " 'terasa',\n",
              " 'terbanyak',\n",
              " 'terdahulu',\n",
              " 'terdapat',\n",
              " 'terdiri',\n",
              " 'terhadap',\n",
              " 'terhadapnya',\n",
              " 'teringat',\n",
              " 'teringat-ingat',\n",
              " 'terjadi',\n",
              " 'terjadilah',\n",
              " 'terjadinya',\n",
              " 'terkira',\n",
              " 'terlalu',\n",
              " 'terlebih',\n",
              " 'terlihat',\n",
              " 'termasuk',\n",
              " 'ternyata',\n",
              " 'tersampaikan',\n",
              " 'tersebut',\n",
              " 'tersebutlah',\n",
              " 'tertentu',\n",
              " 'tertuju',\n",
              " 'terus',\n",
              " 'terutama',\n",
              " 'tetap',\n",
              " 'tetapi',\n",
              " 'tiap',\n",
              " 'tiba',\n",
              " 'tiba-tiba',\n",
              " 'tidak',\n",
              " 'tidakkah',\n",
              " 'tidaklah',\n",
              " 'tiga',\n",
              " 'tinggi',\n",
              " 'toh',\n",
              " 'tunjuk',\n",
              " 'turut',\n",
              " 'tutur',\n",
              " 'tuturnya',\n",
              " 'ucap',\n",
              " 'ucapnya',\n",
              " 'ujar',\n",
              " 'ujarnya',\n",
              " 'umum',\n",
              " 'umumnya',\n",
              " 'ungkap',\n",
              " 'ungkapnya',\n",
              " 'untuk',\n",
              " 'usah',\n",
              " 'usai',\n",
              " 'waduh',\n",
              " 'wah',\n",
              " 'wahai',\n",
              " 'waktu',\n",
              " 'waktunya',\n",
              " 'walau',\n",
              " 'walaupun',\n",
              " 'wong',\n",
              " 'yaitu',\n",
              " 'yakin',\n",
              " 'yakni',\n",
              " 'yang']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}